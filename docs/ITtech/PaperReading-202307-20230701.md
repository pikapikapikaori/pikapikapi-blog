# 论文阅读 2023.07

> 本文首发于个人博客 \
> 发表日期：\
> 最后编辑于：{docsify-last-updated}

## The Multiplayer Colonel Blotto Game

文章对经典的上校博弈游戏的自然多人泛化进行了研究。文章定义了多人的上校博弈，同时针对不同的玩家数量$k$与战线数量$n$导出了纳什均衡。

### 上校博弈

上校博弈是一个两人参与的零和博弈。

形式化的，考虑玩家A和B，他们需要在$n$个战线中竞争，每个战线俱有价值$v_1,\dots,v_n$。A和B都有有限的预算$\mathcal{B}_A$、$\mathcal{B}_B$，其可以用于分配在不同战场。他们需要同时决定在每个战场上投入多少预算。对特定战场，在该战场上投入预算较多的一方获胜。玩家的目标是使赢得的战场的价值总和最大化。通常情况下，为了保证对称性（symmetric），会要求$\mathcal{B}_A=\mathcal{B}_B, v_1= \dots =v_n$。

这一博弈并不存在纯策略纳什均衡。目前对其均衡的多数研究都是根据一般乐透博弈（General Lotto）来计算的。在此博弈中每个玩家在战场上分配的预算是一个分布而非一个数值，而最终目标则是使战场收益期望最大化（或是是单样本收益最大化）。

### 多人上校博弈

文章首先定义了多人上校博弈。

多人上校博弈由$(k\in\mathbb{N},n\in\mathbb{N},\vec{\mathcal{B}}\in\mathbb{R}^n_{\geq0},\vec{v}\in\mathbb{R}^n_{\geq0})$指定。其中$k$代表玩家数量，$n$代表战场数量，$\vec{\mathcal{B}}$是全部玩家预算的向量，$\vec{v}$是战场价值的向量。战场价值总和可以表示为$V=\Vert\vec{v}\Vert_1=\sum^n_{j=1} v_j$。

每个玩家对战场的投标表示为向量$A_{i,*}=(A_{i,1},\dots,A_{i,n})\in\mathbb{R}^n_{\geq0}$，其满足约束$\Vert A_{i,*}\Vert_1=\sum_{j\in [n]} A_{i,j}\leq\mathcal{B}_i$。

令投标矩阵为$A=(A_{i,j})_{(i,j)\in[k]\times[n]}$（显然第$i$行$j$列代表$i$玩家在$j$战场的投标）。对任意$i\in[k]$有玩家的收益为：

$$
U_i(A):=\sum_{j\in[n]}U_{i,j}(A):=\sum_{j\in[n]} v_j \cdot (\frac{f(i)}{\vert \argmax_{i'} A_{i',j}\vert})
$$

其中：
$$
f(i)=\begin{dcases}
   1 &\text{if } i \in \argmax_{i' \in [k]} A_{i',j} \\
   0 &\text{if } i \notin \argmax_{i' \in [k]} A_{i',j}
\end{dcases}
$$

换言之每个战场的价值有出价最高的玩家平分。

论文中将每个玩家预算相同的情况定义为对称（symmetric），将战场价值都相等的情况定位为同质（homogeneous）。

### 多人一般乐透博弈

更一般的，文章定义了多人一般乐透博弈$(k\geq2,n,\vec{\mathcal{B}},\vec{v})$，其中玩家$i$在战场$j$上指定一个分布$\mathcal{D}_{i,j}$，其满足约束条件$\sum^n_{j=1}\mathbb{E}_{A_{i,j}\sim\mathcal{D}_{i,j}}[A_{i,j}]\leq\mathcal{B}_i$。显然此时玩家$i$的收益为$\mathbb{E}_AU_i(A)$。

考虑连续的对称多人一般乐透博弈，其由$(k\geq2,n,\vec{\mathcal{B}}=1,\vec{v})$指定。文章指出，当玩家$i$在战场$j$上的分布为$\mathcal{D}_{i,j}=\frac{kv_j}{V}\cdot Beta(\frac{1}{k-1},1)$时，是一个纳什均衡。

### 多人上校博弈均衡算法

基于多人一般乐透博弈的该均衡，文章考虑对称的上校博弈。假如对战场有一个k-分区使得各个分区中战场价值总和相同，那么玩家可以根据特定算法达到纳什均衡。更具体的，计算一个分布$(X_1,\dots,X_k)\sim Dir(\frac{1}{k-1},\dots,\frac{1}{k-1})$，那么达到均衡时玩家指定的分布应是$(A_1,\dots,A_n),A_j \leftarrow (\frac{kv_j}{V}\cdot X_{\pi(j)})$。

更具体的，文章还对上述博弈在玩家数$k=3$时计算了更细致的均衡情况。

文章最后考虑玩家预算都为整数，且玩家在战场上的投标只为布尔值的情况，并根据前述的结论计算出了这一博弈下的均衡。

## Evolutionary Game Theory Squared: Evolving Agents in Endogenously Evolving Zero-Sum Games

*没太看懂，看了一下大致内容，可能需要学习下微分几何和动力学以后再看。*

进化博弈论的主要范式基于在给定的固定、静态博弈中动态的智能体群体之间的明显差异——也即重复博弈在演化过程中不同类型群体在静态的阶段博弈中所会采取的策略集的差异。文章关注于这样一种情况，即在演化过程中无论是参与博弈的参与者还是博弈本身都会随着时间的推移而演化（类似于神经网络，博弈规则本身可以接收智能体的历史选择与收益来对规则与支付等方面进行改变）。

文章利用在进化博弈论中最被广泛研究应用的复制器动力学（replicator dynamics，可以粗略地理解为高于平均价值的策略会被模仿）来研究重复的零和博弈。在这一系统之中，智能体群体在零和博弈中竞争的过程中，竞争本身也会对抗性地进化。文章指出，在这一系统中存在多种规律性：

1. 该系统遵守信息论守恒定律，其与智能体群体及博弈本身都相关。
2. 该系统是庞加莱回归的（Poincaré recurrent），包含智能体与博弈本身的系统的所有可能的初始状态都位于循环轨道上。这一系统经过足够长的时间后，会到达一个接近初始态的状态。
3. 尽管该系统永远无法达到均衡，但智能体的时间平均行为与时间平均效用收敛于演化博弈的时间平均纳什均衡。

文章最后提供了一种多项式时间算法，来预测任何此类协同演化网络博弈的上述时间平均量。

### 多矩阵博弈与复制器动力学定义

多玩家的多矩阵博弈以无向图$G=(V,E),\vert V\vert=N$定义，节点集代表玩家的集合，玩家间若进行$2\times2$矩阵博弈那么代表这两个玩家的节点之间就存在一条边。智能体$i\in V$利用混合策略以分布$x_i$从决策集$\mathcal{A}_i=\{1,\dots,n_i\}$种选择决策。其中混合策略集$\mathcal{X}_i$是$\mathbb{R}^{n_i}$的标准单形，$\mathcal{X}_i=\Delta^{n_i-1}=\{x_i\in\mathbb{R}^{n_i}_{\geq 0}:\sum_{\alpha\in\mathcal{A}_i}x_{i\alpha}=1\}$，$x_{i\alpha}$表示玩家$i$采取行动$\alpha\in\mathcal{A}_i$的概率质量。理所当然的，博弈的状态以全部玩家策略的连接（concatenation）定义，全部可能的策略配置集合为策略空间$\mathcal{X}=\prod_{i\in V}\mathcal{X}_i$。

边$(i,j)$表示的$2\times2$矩阵博弈以一对矩阵$A^{ij}\in\mathbb{R}^{n_i\times n_j}$与$A^{ji}\in\mathbb{R}^{n_j\times n_i}$描述。从定义很显然地可以知道矩阵中的任意一项$A^{ij}_{\alpha\beta},\forall(\alpha,\beta)\in\mathcal{A}_i\times\mathcal{A}_j$表示玩家$i$采取策略$\alpha$且玩家$j$采取策略$\beta$时前者的收益。文中的建模提到在这种系统中允许自环，即允许玩家向自己发起博弈。玩家$i\in V$在策略配置$x\in\mathcal{X}$下的效用/收益$u_i(x)$显然与该玩家参与的全部博弈中的收益和相关。更具体的，

$$
u_i(x)=\sum_{j:(i,j)\in E}x^{\top}_iA^{ij}x_j
$$

文章进一步作了如下定义：$u_{i\alpha}(x)=\sum_{j:(i,j)\in E}(A^{ij}x_j)_{\alpha}$代表玩家$i\in V$在策略配置$x=(\alpha,x_{-i})\in\mathcal{X},\alpha\in\mathcal{A}_i$下的效用。如果对全部$x\in\mathcal{X}$有$\sum_{i\in V}u_i(x)$那么博弈是零和的。如果有正系数$\{\eta_i\}_{i\in V}$使得$\sum_{i\in V}\eta_iu_i(x)=0$对全部$x\in\mathcal{X}$都成立，切所有的自环都是反对称的（antisymmetric，$A^{ii}=-(A^{ii})^{\top}$），那么博弈是调节过的零和的（rescaled zero-sum）。

对$x^*_i\in\mathcal{X}_i$的支撑$supp(x^*_i)=\{\alpha\in\mathcal{A}_i:x_{i\alpha}>0\}$，如果$supp(x^*_i)=\mathcal{A}_i,\forall i\in V$，那么$x^*$达到的纳什均衡是完全纳什均衡。

传统的复制器动力学系统被定义为$\dot{x}_{i\alpha}=x_{i\alpha}(u_{i\alpha}(x)-u_i(x)),\alpha\in\mathcal{A}_i$（单位时间内采取策略$\alpha$的博弈者频率的期望变化量）。为了便于后续计算这一方程可以被简化为如下的矩阵形式：

$$
\dot{x}_i=x_i\cdot(\sum_{j:(i,j)\in E}A^{ij}x_j-(\sum_{j:(i,j)\in E}x^{\top}_iA^{ij}x_j)\cdot 1)
$$

其中$1$表示全由$1$组成的$n_i$维向量。

### 双重进化过程

文章指出，事实上无论是目前热门的机器学习领域还是生物学领域都存在这种智能体与博弈的双重进化过程。在这样的动力系统中，存在随时间演化的被抽样种群，以及取决于这一种群的环境参数。一方面，在AI & ML中，尽管生成器参数一开始就已确定，然而判别起的参数却是随着学习而被更新。生成器与判别器可以被视为遵循进化动力学的群体。另一方面，在生物学领域，无论是研究种群数量的协调水平还是研究资源可用性调节种群间竞争，环境参数都会随时间推移而演变。

着重考虑物种间竞争资源的动力系统，对于$n$个种群中的种群$i\in\{1,\dots,n\}$，环境变量$w$和种群数量$y$的单形的内部初始条件有：

$$
\begin{align*}
   \dot{w}_i &= w_i\sum^n_{j=1}w_j(y_j-y_i) \\
   \dot{y}_i &= y_i((P(w)y)_i-y^{\top}P(w)y)
\end{align*}
$$

其中$P(w)=P+\mu W,\mu>0$，$P$被定义为一般化的RPS（猜拳）支付矩阵：

$$
P=\begin{pmatrix}
0 & -1 & 0 & \dots & 0 & 0 & 1 \\
1 & 0 & -1 & \dots & 0 & 0 & 0 \\
\dots & \dots & \dots & \dots & \dots & \dots & \dots \\
0 & 0 & 0 & \dots & 1 & 0 & -1 \\
-1 & 0 & 0 & \dots & 0 & 1 & 0 
\end{pmatrix}
$$

环境变量矩阵为：

$$
W=\begin{pmatrix}
0 & w_1-w_2 &  \dots & w_1-w_n \\
w_2-w_1 & 0 & \dots & w_2-w_n \\
\dots & \dots  & \dots & \dots \\
w_n-w_1 & w_n-w_2 & \dots & 0 
\end{pmatrix}
$$

文章指出，这一随时间演化的RPS博弈实质上相当于两人调节过的零和博弈中的复制器动力系统。在此基础上，文章进一步作出了规约，并证明能由如下的动力学方程定义的随时间演化的系统都与多矩阵博弈中的复制器动力学系统相同：

$$
\begin{align*}
   \dot{w}_{k,i} &= w_{k,i}\sum_{l\in\mathcal{N}^w_k}\sum_j w_{k,j}((A^{k,l}y_l)_i-(A^{k,l}y_l)_j) \\
   \dot{y}_{l,i} &= y_{l,i}((P_l(w)y_l)_i-y^{\top}_lP_l(w)y_l)
\end{align*}
$$

其中$y=(y_1,\dots,y_{n_y})$，$w=(w_1,\dots,w_{n_w})$。$y_l\in\Delta^{n-1},\forall l\in\{1,\dots,n_y\}$，$w_k\in\Delta^{n-1},\forall k\in\{1,\dots,n_w\}$。环境仅随种群演化，种群紧随环境与种群本身演化。$\mathcal{N}^w_k$为与$w_k$一起进化的种群集合，$\mathcal{N}^y_l$为与$y_l$一起进化的环境集合。$P_l(w)=P_l+\sum_{k\in\mathcal{N}^y_l}W^{l,k},P_l\in\mathbb{R}^{n\times n},W^{l,k}\in\mathbb{R}^{n\times n}$。第$(i,j)$项为$(A^{l,k}w_k)_i-(A^{l,k}w_k)_j$。

由于这种简化使得环境变量也可以视为参与博弈的种群，因而这种动态的系统也可以像分析静态博弈中的动态智能体的系统那样进行分析。

## 参考资料

### 参考文献（阅读的论文，按文中序）

1. Enric Boix-Adserà, Benjamin L. Edelman, and Siddhartha Jayanti. 2020. The Multiplayer Colonel Blotto Game. In Proceedings of the 21st ACM Conference on Economics and Computation (EC '20). Association for Computing Machinery, New York, NY, USA, 47–48. https://doi.org/10.1145/3391403.3399555
2. Skoulakis, S., Fiez, T., Sim, R., Piliouras, G., & Ratliff, L. (2021, May 18). Evolutionary Game Theory Squared: Evolving Agents in Endogenously Evolving Zero-Sum Games. Proceedings of the AAAI Conference on Artificial Intelligence, 35(13), 11343–11351. https://doi.org/10.1609/aaai.v35i13.17352

### 其他资料

1. Kovenock, D., & Roberson, B. (2020, June 20). Generalizations of the General Lotto and Colonel Blotto games. Economic Theory, 71(3), 997–1032. https://doi.org/10.1007/s00199-020-01272-2
2. Recurrence and Topology. (2007, July 30). https://doi.org/10.1604/9780821842348
